{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a237264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "\n",
    "def search_google_scholar_url(name, university, max_results=10):\n",
    "    query = f\"{name} {university} google scholar\"\n",
    "    print(f\"üîç Searching: {query}\")\n",
    "    results = list(search(query, num_results=max_results))\n",
    "    for url in results:\n",
    "        if \"scholar.google.com/citations?\" in url:\n",
    "            print(f\"‚úÖ Found Google Scholar profile: {url}\")\n",
    "            return url\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aec00ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_scholar_profile(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return BeautifulSoup(response.text, 'html.parser')\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"‚ùå Failed to fetch page: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5544603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scholar_profile(soup):\n",
    "    if soup is None:\n",
    "        return None\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    # Name & affiliation\n",
    "    data['name'] = soup.find('div', id='gsc_prf_in').text.strip() if soup.find('div', id='gsc_prf_in') else \"Unknown\"\n",
    "    data['affiliation'] = soup.find('div', class_='gsc_prf_il').text.strip() if soup.find('div', class_='gsc_prf_il') else \"N/A\"\n",
    "\n",
    "    # Metrics\n",
    "    metrics = soup.find_all('td', class_='gsc_rsb_std')\n",
    "    data['citations'] = metrics[0].text if len(metrics) >= 1 else \"N/A\"\n",
    "    data['h_index'] = metrics[2].text if len(metrics) >= 3 else \"N/A\"\n",
    "\n",
    "    # Publications\n",
    "    articles = soup.find_all('tr', class_='gsc_a_tr')[:5]\n",
    "    publications = []\n",
    "    for article in articles:\n",
    "        title_tag = article.find('a', class_='gsc_a_at')\n",
    "        title = title_tag.text.strip() if title_tag else \"Untitled\"\n",
    "        link = f\"https://scholar.google.com{title_tag['href']}\" if title_tag else \"\"\n",
    "        authors_tag = article.find('div', class_='gs_gray')\n",
    "        authors = authors_tag.text.strip() if authors_tag else \"\"\n",
    "\n",
    "        # ‚úÖ Extract year\n",
    "        year_tag = article.find('span', class_='gsc_a_h')\n",
    "        year = int(year_tag.text.strip()) if year_tag and year_tag.text.strip().isdigit() else None\n",
    "\n",
    "        publications.append({\n",
    "            'title': title,\n",
    "            'link': link,\n",
    "            'authors': authors,\n",
    "            'year': year  # ‚úÖ Include year in the publication dict\n",
    "        })\n",
    "\n",
    "    data['publications'] = publications\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06bb504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_as_markdown(profile):\n",
    "    if profile is None:\n",
    "        return \"‚ùå Could not parse Google Scholar profile.\"\n",
    "\n",
    "    md = f\"# {profile['name']}\\n\"\n",
    "    md += f\"**Affiliation**: {profile['affiliation']}\\n\\n\"\n",
    "    md += f\"- **Citations**: {profile['citations']}\\n\"\n",
    "    md += f\"- **h-index**: {profile['h_index']}\\n\\n\"\n",
    "    md += \"## Recent Publications\\n\"\n",
    "    for pub in profile['publications']:\n",
    "        md += f\"- [{pub['title']}]({pub['link']})\"\n",
    "        if pub.get('year'):\n",
    "            md += f\" ({pub['year']})\"\n",
    "        md += \"\\n\"\n",
    "        md += f\"  - _{pub['authors']}_\\n\"\n",
    "    return md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "675cf7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs, urlencode\n",
    "\n",
    "def transform_scholar_url(original_url):\n",
    "    parsed = urlparse(original_url)\n",
    "    query_params = parse_qs(parsed.query)\n",
    "\n",
    "    # Add or overwrite required parameters\n",
    "    query_params['view_op'] = ['list_works']\n",
    "    query_params['sortby'] = ['pubdate']\n",
    "\n",
    "    # Flatten query string (each param should be a string, not list)\n",
    "    flat_query = {k: v[0] for k, v in query_params.items()}\n",
    "\n",
    "    new_query = urlencode(flat_query)\n",
    "    transformed_url = f\"{parsed.scheme}://{parsed.netloc}{parsed.path}?{new_query}\"\n",
    "    \n",
    "    return transformed_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b30d89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scholar_markdown(name, university):\n",
    "    url_og = search_google_scholar_url(name, university)\n",
    "    if not url_og:\n",
    "        return None\n",
    "\n",
    "    url = transform_scholar_url(url_og)\n",
    "    soup = fetch_scholar_profile(url)\n",
    "    profile_data = parse_scholar_profile(soup)\n",
    "\n",
    "    # ‚úÖ Check if most recent paper is from 2023 or later\n",
    "    years = [pub['year'] for pub in profile_data['publications'] if isinstance(pub['year'], int)]\n",
    "    if not years or max(years) < 2023:\n",
    "        return None\n",
    "\n",
    "    return format_as_markdown(profile_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e140f2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching: Rafiou Agoro Tufts google scholar\n",
      "‚úÖ Found Google Scholar profile: https://scholar.google.com/citations?user=m9-daTcAAAAJ&hl=en\n",
      "\n",
      "--- Google Scholar Markdown ---\n",
      "\n",
      "# Rafiou Agoro\n",
      "**Affiliation**: The Jackson Laboratory\n",
      "\n",
      "- **Citations**: 745\n",
      "- **h-index**: 14\n",
      "\n",
      "## Recent Publications\n",
      "- [Dynamic single cell transcriptomics defines kidney FGF23/KL bioactivity and novel segment-specific inflammatory targets.](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=m9-daTcAAAAJ&sortby=pubdate&citation_for_view=m9-daTcAAAAJ:aqlVkmm33-oC) (2025)\n",
      "  - _R Agoro, J Myslinski, YG Marambio, D Janosevic, KN Jennings, S Liu, ..._\n",
      "- [Phosphorus-independent role of FGF23 in erythropoiesis and iron homeostasis](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=m9-daTcAAAAJ&sortby=pubdate&citation_for_view=m9-daTcAAAAJ:9ZlFYXVOiuMC) (2024)\n",
      "  - _MY Park, R Agoro, SS Jankauskas, C Le Henaff, D Sitara_\n",
      "- [Challenges and opportunities for conceiving genetically diverse sickle cell mice](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=m9-daTcAAAAJ&sortby=pubdate&citation_for_view=m9-daTcAAAAJ:mVmsd5A6BfQC) (2024)\n",
      "  - _R Agoro, GA Churchill_\n",
      "- [The klotho F/C AD risk haplotype drives distinct phenotypes in a novel mouse model](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=m9-daTcAAAAJ&sortby=pubdate&citation_for_view=m9-daTcAAAAJ:4DMP91E08xMC) (2024)\n",
      "  - _M Sasner, RS Pandey, KP Kotredes, D Garceau, C Weber, R Agoro, ..._\n",
      "- [Induced hypophosphatemia causes genomic reprogramming across the osteolineage as detected by single-cell RNAseq](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=m9-daTcAAAAJ&sortby=pubdate&citation_for_view=m9-daTcAAAAJ:ZeXyd9-uunAC) (2024)\n",
      "  - _E Solis, S Sulayman, R Agoro, K Jennings, Y Marambio, S Liu, J Wan, ..._\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example input\n",
    "name = \"Rafiou Agoro\"\n",
    "university = \"Tufts\"\n",
    "\n",
    "markdown = get_scholar_markdown(name, university)\n",
    "print(\"\\n--- Google Scholar Markdown ---\\n\")\n",
    "print(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5db77ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_titles(markdown: str) -> str:\n",
    "    # Find all titles in square brackets\n",
    "    titles = re.findall(r'\\[(.*?)\\]', markdown)\n",
    "    # Join them into one string separated by periods or semicolons\n",
    "    return '. '.join(titles)\n",
    "\n",
    "titles = extract_titles(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b6a3899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_first_paper_info(markdown: str):\n",
    "    # Match the first markdown-style link: [Title](URL)\n",
    "    match = re.search(r'\\[(.*?)\\]\\((.*?)\\)', markdown)\n",
    "    if match:\n",
    "        title, link = match.group(1), match.group(2)\n",
    "        return title, link\n",
    "    else:\n",
    "        return None, None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
